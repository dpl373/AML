{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XRzshApmWleY"
   },
   "source": [
    "## Optional task 07.2: Data Augmentation\n",
    "\n",
    "ITU KSADMAL1KU - Advanced Machine Learning for Computer Science 2023\n",
    "\n",
    "by Stefan Heinrich, with material by Kevin Murphy.\n",
    "\n",
    "This notebook is based on sec 13.1 of http://d2l.ai/chapter_computer-vision/image-augmentation.html and further adaptations by Kevin Murphy in https://github.com/probml/probml-notebooks/blob/main/notebooks-d2l/image_augmentation_torch.ipynb\n",
    "\n",
    "All info and static material: https://learnit.itu.dk/course/view.php?id=3022225\n",
    "\n",
    "-------------------------------------------------------------------------------\n",
    "\n",
    "We illustrate some simple data augmentation methods form images."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MHkEXYIbWL6W"
   },
   "source": [
    "# @title #### Import dependencies\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(seed=1)\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "\n",
    "!mkdir figures # for saving plots\n",
    "\n",
    "!pip install matplotlib_inline\n",
    "!wget https://raw.githubusercontent.com/d2l-ai/d2l-en/master/d2l/torch.py -q -O d2l.py\n",
    "import d2l"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Dmk7eNdrWnA9"
   },
   "source": [
    "d2l.set_figsize()\n",
    "#img = d2l.Image.open('../img/cat1.jpg')\n",
    "\n",
    "#url = 'https://github.com/d2l-ai/d2l-en/blob/master/img/cat1.jpg?raw=true'\n",
    "url = 'https://github.com/probml/probml-notebooks/blob/main/images/cat_dog.jpg?raw=true'\n",
    "fname = 'img.jpg'\n",
    "!wget $url -q -O $fname\n",
    "\n",
    "\n",
    "img = d2l.Image.open(fname)\n",
    "\n",
    "d2l.plt.imshow(img);"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YPFwgaY_e4o1"
   },
   "source": [
    "def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):\n",
    "    \"\"\"Plot a list of images.\"\"\"\n",
    "    figsize = (num_cols * scale, num_rows * scale)\n",
    "    fig, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    for i, (ax, img) in enumerate(zip(axes, imgs)):\n",
    "        if torch.is_tensor(img):\n",
    "            # Tensor Image\n",
    "            ax.imshow(img.numpy())\n",
    "        else:\n",
    "            # PIL Image\n",
    "            ax.imshow(img)\n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "        if titles:\n",
    "            ax.set_title(titles[i])\n",
    "    plt.tight_layout()\n",
    "    return fig, axes"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Hnk_4jTXJ6t"
   },
   "source": [
    "To visualize an image augmentation, which may be stochastic, we apply it multiple times to an image.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ViWltqFPXK5T"
   },
   "source": [
    "\n",
    "def apply(img, aug, num_rows=1, num_cols=4, scale=2):\n",
    "    Y = [aug(img) for _ in range(num_rows * num_cols)]\n",
    "    fig, axes = show_images(Y, num_rows, num_cols, scale=scale)\n",
    "    return fig, axes"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wHSpLphPXX7w"
   },
   "source": [
    "#### Flipping"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dOfXdCB4XYsP"
   },
   "source": [
    "apply(img, torchvision.transforms.RandomHorizontalFlip())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kcTMBFt6XZTc"
   },
   "source": [
    "apply(img, torchvision.transforms.RandomVerticalFlip())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F53SuTQpXr63"
   },
   "source": [
    "#### Crop and resize\n",
    "\n",
    "Below, we randomly crop a region with an area of 10% to 100% of the original area, and the ratio of width to height of the region is randomly selected from between 0.5 and 2. Then, the width and height of the region are both scaled to 200 pixels. \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wAnkJLjMXqln"
   },
   "source": [
    "shape_aug = torchvision.transforms.RandomResizedCrop(\n",
    "    (200, 200), scale=(0.1, 1), ratio=(0.5, 2))\n",
    "apply(img, shape_aug)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SGXiBO7PdqiL"
   },
   "source": [
    "shape_aug = torchvision.transforms.RandomResizedCrop(\n",
    "    (200, 200), scale=(0.5, 1), ratio=(1, 1))\n",
    "fig, axes = apply(img, shape_aug)\n",
    "fig.savefig('dog_cat_augment.png')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rjO-R8l2YI6w"
   },
   "source": [
    "#### Changing color\n",
    "\n",
    "We can change brightness, contrast, saturation and hue.\n",
    "First we change brightness, from 1-0.5=0.5 times less to 1+0.5=1.5 times more."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AcrnnvKxX_Hu"
   },
   "source": [
    "apply(\n",
    "    img,\n",
    "    torchvision.transforms.ColorJitter(brightness=0.5, contrast=0,\n",
    "                                       saturation=0, hue=0))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_MtkzuxYd2W"
   },
   "source": [
    "Now we change hue."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "87QsG4iRYehk"
   },
   "source": [
    "apply(\n",
    "    img,\n",
    "    torchvision.transforms.ColorJitter(brightness=0, contrast=0, saturation=0,\n",
    "                                       hue=0.5))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lw5aKuh9YgDP"
   },
   "source": [
    "Now we change saturation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6JGNK9UuYfHc"
   },
   "source": [
    "apply(\n",
    "    img,\n",
    "    torchvision.transforms.ColorJitter(brightness=0, contrast=0, saturation=0.5,\n",
    "                                       hue=0))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwT0NxPmYm7z"
   },
   "source": [
    "Now we change contrast."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iIHucho-Yj0q"
   },
   "source": [
    "apply(\n",
    "    img,\n",
    "    torchvision.transforms.ColorJitter(brightness=0, contrast=0.5, saturation=0,\n",
    "                                       hue=0))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZK46MZfXYtiT"
   },
   "source": [
    "Now we change all of them."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "96DSwPZhYpZU"
   },
   "source": [
    "color_aug = torchvision.transforms.ColorJitter(brightness=0.5, contrast=0.5,\n",
    "                                               saturation=0.5, hue=0.5)\n",
    "apply(img, color_aug)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6B-m6MFuY4Rx"
   },
   "source": [
    "#### Combining multiple augmentations in a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "15Md8QlfYzof"
   },
   "source": [
    "augs = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomHorizontalFlip(), color_aug, shape_aug])\n",
    "apply(img, augs)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RFooEcBbgwaq"
   },
   "source": [
    "augs = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomHorizontalFlip(), shape_aug])\n",
    "fig, axes = apply(img, augs)\n",
    "fig.savefig('dog_cat_augment2.png')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qE9v8ePHZGMp"
   },
   "source": [
    "#### Using augmentations in a dataloader\n",
    "\n",
    "We illustrate how we can transform training and test images from CIFAR10."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XCxDuARqY6Om"
   },
   "source": [
    "all_images = torchvision.datasets.CIFAR10(train=True, root=\"../data\",\n",
    "                                          download=True)\n",
    "d2l.show_images([all_images[i][0] for i in range(32)], 4, 8, scale=0.8);"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xWc_aZ5EZLfZ"
   },
   "source": [
    "train_augs = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor()])\n",
    "\n",
    "test_augs = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor()])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9ZqpRWixZPEc"
   },
   "source": [
    "def load_cifar10(is_train, augs, batch_size):\n",
    "    dataset = torchvision.datasets.CIFAR10(root=\"../data\", train=is_train,\n",
    "                                           transform=augs, download=True)\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=is_train,\n",
    "        num_workers=d2l.get_dataloader_workers())\n",
    "    return dataloader"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "T2LLZXMeZRgU"
   },
   "source": [
    "train_iter = load_cifar10(True, train_augs, 32)\n",
    "dataiter = iter(train_iter)\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "images, labels = next(dataiter)\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "images, labels = next(dataiter)\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# for i, (features, labels) in enumerate(train_iter):\n",
    "#   print(i)\n",
    "#   print(features.shape)\n",
    "#   plt.imshow(np.transpose(features[0], (1,2,0)), interpolation='nearest')\n",
    "#   if i>=1: break"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}
