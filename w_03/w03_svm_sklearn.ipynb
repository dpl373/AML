{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Week 3 Exercise: kernel SVM\n",
    "\n",
    "Advanced Machine Learning for KCS\n",
    "\n",
    "\n",
    "\n",
    "-------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*The goal is to implement and evaluate different kernels for SVMs for one dataset.*\n",
    "*We start by importing the necessary libraries.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, svm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# this code is only for suppressing a very specific warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', 'Solver terminated early.*')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Creating dataset\n",
    "\n",
    "We generate our random dataset; this will be 2D data that is not linearly separable. In fact, the data will follow concentric rings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "N = 200 # number of samples\n",
    "c = 0.5 # scale factor between inner and outer circles\n",
    "noise = 0.1 # noise parameter\n",
    "\n",
    "# generate data\n",
    "x_vals, t_vals = datasets.make_circles(n_samples=N, factor=c, noise=noise)\n",
    "# if a value in y_vals is 1, we leave it at one, but if it is 0, we set it to -1\n",
    "t_vals = np.where(t_vals, 1, -1)\n",
    "\n",
    "class1_idxs = np.flatnonzero(t_vals == 1)\n",
    "class1_x = x_vals[class1_idxs]\n",
    "class1_t = t_vals[class1_idxs]\n",
    "class2_idxs = np.flatnonzero(t_vals == -1)\n",
    "class2_x = x_vals[class2_idxs]\n",
    "class2_t = t_vals[class2_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can take a quick look at our data to get a sense of what we're trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# matplotlib:\n",
    "plt.scatter(class1_x[:, 0], class1_x[:, 1],\n",
    "            label = \"Class 1 (+1)\",\n",
    "            color = \"none\",\n",
    "            edgecolor = \"red\"\n",
    "           )\n",
    "plt.scatter(class2_x[:, 0], class2_x[:, 1],\n",
    "            label = \"Class 2 (-1)\",\n",
    "            color = \"none\",\n",
    "            edgecolor = \"blue\"\n",
    "           )\n",
    "plt.legend(loc=\"upper left\", framealpha=0.25)\n",
    "plt.show()\n",
    "# simpler with seaborn:\n",
    "plot_raw = sns.scatterplot(x=x_vals[:,0], y=x_vals[:, 1],\n",
    "                           hue=t_vals, palette=\"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task:\n",
    "### (a)\n",
    "*Implement:*\n",
    "* *a linear kernel:* $K(\\mathbf{x}_1, \\mathbf{x}_2) = \\mathbf{x}_1^\\intercal \\mathbf{x}_2$\n",
    "* *a Gaussian or radial basis function (RBF) kernel:* $K(\\mathbf{x}_1, \\mathbf{x}_2) = e^{(-\\gamma \\|\\mathbf{x}_1 - \\mathbf{x}_2 \\|^2)}$\n",
    "* *a polynomial kernel:* $K(\\mathbf{x}_1, \\mathbf{x}_2) = (\\mathbf{x}_1^\\intercal \\mathbf{x}_2 + c)^d$\n",
    "\n",
    "#### Here can can write your solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "type='linear'\n",
    "\n",
    "def my_kernel(x, t):\n",
    "    #x is matrix over all dimensions x1, x2, ...\n",
    "\n",
    "    kernel = None\n",
    "    if type=='linear':\n",
    "        # linear kernel\n",
    "        # *CODE FOR LINEAR KERNEL*\n",
    "        #kernel = *kernel output value*\n",
    "        kernel = None  #remove\n",
    "\n",
    "    elif type=='gaussian':\n",
    "        # Gaussian (RBF) kernel\n",
    "        # *CODE FOR GAUSSIAN (RBF) KERNEL*\n",
    "        #kernel = *kernel output value*\n",
    "        kernel = None  #remove\n",
    "\n",
    "\n",
    "    elif type=='polynomial':\n",
    "        # polynomial kernel\n",
    "        # *CODE FOR POLYNOMIAL KERNEL*\n",
    "        #kernel = *kernel output value*\n",
    "        kernel = None  #remove\n",
    "\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Perform optimisation of the SVM via a manual iteration\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.decision_function\n",
    "We start the training loop for the SVM.  We will randomly choose a batch of points and run the train step.  Then we calculate the loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# set up the SVM model\n",
    "# we use max_iter=1 so that we can iterate manually below\n",
    "clf = svm.SVC(kernel=my_kernel, max_iter=1, tol=0.001)\n",
    "batch_size = N  # we start with a batch size equal of the dataset size, but we can try out smaller ones!\n",
    "epochs = 10000\n",
    "\n",
    "# training loop\n",
    "temp_losses = []\n",
    "batch_accs = []\n",
    "np.random.seed(0) # set this for your experiments to compare the different kernels\n",
    "for i in range(epochs):\n",
    "    # generate random indices equal to batch_size\n",
    "    batch_idxs = np.random.choice(N, size=batch_size)\n",
    "    # get the corresponding input and target points\n",
    "    batch_x = x_vals[batch_idxs]\n",
    "    batch_t = t_vals[batch_idxs][:,]\n",
    "    #print(np.shape(batch_x), np.shape(batch_t))\n",
    "\n",
    "    # train the model with this batch\n",
    "    clf.fit(batch_x, batch_t)\n",
    "\n",
    "    # calculate temporary train accuracy\n",
    "    accuracy = clf.score(batch_x, batch_t)\n",
    "    batch_accs.append(accuracy)\n",
    "\n",
    "    if (i+1)%1000==0:\n",
    "        print(\"Step #{}\".format(i+1))\n",
    "        print(\"Accuracy = \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*To plot a pretty picture of the regions we fit, we create a fine mesh to run through our model and get the predictions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# find boundaries for contour plot\n",
    "abscissa_min, abscissa_max = x_vals[:, 0].min()-1, x_vals[:, 0].max()+1\n",
    "ordinate_min, ordinate_max = x_vals[:, 1].min()-1, x_vals[:, 1].max()+1\n",
    "\n",
    "# generate mesh grid of points\n",
    "#h = .025  # step size in the mesh\n",
    "#xx, yy = np.meshgrid(np.arange(abscissa_min, abscissa_max, h), np.arange(ordinate_min, ordinate_max, h))\n",
    "xx, yy = np.meshgrid(\n",
    "    np.linspace(abscissa_min, abscissa_max, 10),\n",
    "    np.linspace(ordinate_min, ordinate_max, 20)\n",
    ")\n",
    "\n",
    "grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "print(np.shape(grid_points))\n",
    "\n",
    "print(xx)\n",
    "print(yy)\n",
    "grid_preds = clf.predict(grid_points)  # this is not a clean way to do and will raise a warning (we only process values here, but trained with dataframes that had names), but for our purpose that's fine\n",
    "grid_preds = grid_preds.reshape(xx.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Then we make the plot of our points and our decision boundary.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_rsk = sns.scatterplot(x=x_vals[:,0], y=x_vals[:,1],\n",
    "                           hue=t_vals, cmap=plt.cm.Paired, palette=\"deep\")\n",
    "plot_rsk.pcolormesh(xx, yy, grid_preds, cmap=plt.cm.Paired, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can also plot the accuracy over the training batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_accs_pd = pd.DataFrame({'Batch': [k for k in range(len(batch_accs))], 'Accuracy': batch_accs})\n",
    "sns.lineplot(data=batch_accs_pd, x=\"Batch\", y=\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task:\n",
    "### (b)\n",
    "*Which of these performs best on the data, in terms of speed and quality? Do not forget to set the random seed to receive reproducible results.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### (c)\n",
    "*Test different values of $c$ and $d$ for the polynomial kernel. Which of them work best?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### (d)\n",
    "*Test different values of $\\gamma$ for the RBF kernel. Which of them works best?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### (e)\n",
    "*Change the part of the code which generates the data such that it becomes linearly separable.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### (f)\n",
    "*Re-evaluate the three kernels. Do you get the same result?*"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "39711fa3f91d767f7faecc7fbab74d0d9168c9fcaf529a8bc1facbd9166a1928"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
