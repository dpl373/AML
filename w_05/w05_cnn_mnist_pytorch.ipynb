{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2: Practising applying a CNN to image data and visualising results\n",
        "\n",
        "Adopted from a notebook by Stefan Heinrich, Noah Brunken Syrkis, with material by Kevin Murphy.\n",
        "\n",
        "-------------------------------------------------------------------------------"
      ],
      "metadata": {
        "collapsed": false,
        "id": "qHde_-0t7lPh",
        "pycharm": {
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "source": [
        "# @title #### import dependencies\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%% Import libraries\n"
        },
        "id": "wIXXaGEJ7lPn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load data set.\n",
        "- Load MNIST"
      ],
      "metadata": {
        "collapsed": false,
        "id": "2sDjxwI97lPq",
        "pycharm": {
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "source": [
        "batch_size = 32"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "WF-q6WFSAs9_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# transformations\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor()])\n",
        "\n",
        "# Create a dataloader for Pytorch training\n",
        "# download and load training dataset\n",
        "trainset = torchvision.datasets.MNIST(root='../data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "# download and load testing dataset\n",
        "testset = torchvision.datasets.MNIST(root='../data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
        "                                         shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "KStcmYUo7lPr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Preprocessing"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "-lAOMrTgAs-C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000\n",
            "10000\n",
            "28\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "print(len(trainset))\n",
        "print(len(testset))\n",
        "img_size = trainloader.dataset.data.shape[1]\n",
        "print(img_size)\n",
        "class_out = trainloader.dataset.targets.unique().size()[0]\n",
        "print(class_out)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5YkpP5BpAs-C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c0141a8-1186-4184-ad00-3b3e277cb42a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Show some data characteristics"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "7d_HhZZDAs-D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "NO_images = 32\n",
        "\n",
        "def imshow(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "dataiter = iter(testloader)\n",
        "images = []\n",
        "for _ in range(NO_images):\n",
        "    # draw some random images from the test set according to the dataloader\n",
        "    image, label = next(iter(dataiter))\n",
        "    image = torch.squeeze(image, 0)\n",
        "    images.append(image)\n",
        "\n",
        "images = torch.stack(images).cpu()\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "vtC42_B7As-E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Build the model\n",
        "\n",
        "Important parameters:\n",
        "\n",
        "**in_channels (int)** — Number of channels in the input image\n",
        "\n",
        "**out_channels (int)** — Number of channels produced by the convolution\n",
        "\n",
        "**kernel_size (int or tuple)** — Size of the convolving kernel\n",
        "\n",
        "**stride (int or tuple, optional)** — Stride of the convolution. Default: 1\n",
        "\n",
        "**padding (int or tuple, optional)** — Zero-padding added to both sides of the input. Default: 0\n",
        "\n",
        "**padding_mode (string, optional)** — ‘zeros’, ‘reflect’, ‘replicate’ or ‘circular’. Default: ‘zeros’\n",
        "\n",
        "**groups (int, optional)** — Number of blocked connections from input channels to output channels. Default: 1\n",
        "\n",
        "**bias (bool, optional)** — If True, adds a learnable bias to the output. Default: True"
      ],
      "metadata": {
        "collapsed": false,
        "id": "x_HjW6lK7lPv",
        "pycharm": {
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def get_output_shape(layer, img_size):\n",
        "    return layer(torch.rand(*(img_size))).data.shape\n",
        "\n",
        "class ModelClass(nn.Module):\n",
        "  def __init__(self, img_size, fc1_out, class_out):\n",
        "      super(ModelClass, self).__init__()\n",
        "\n",
        "      self.conv_layer = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
        "      flatten_size_conv_layer = np.prod(list(get_output_shape(self.conv_layer, (batch_size, 1, img_size, img_size)))) // batch_size\n",
        "\n",
        "      self.linear_layer_1 = nn.Linear(in_features=flatten_size_conv_layer, out_features=fc1_out)\n",
        "      self.linear_layer_2 = nn.Linear(in_features=fc1_out, out_features=class_out)\n",
        "\n",
        "  def forward(self, img):\n",
        "\n",
        "    img = self.conv_layer(img)\n",
        "    img = F.relu(img)\n",
        "\n",
        "    #Start_dim = 1 because we pass batches\n",
        "    flattened = img.flatten(start_dim=1)\n",
        "\n",
        "    x = self.linear_layer_1(flattened)\n",
        "    x = F.relu(x)\n",
        "\n",
        "    x = self.linear_layer_2(x)\n",
        "    x = F.softmax(x, dim=1)\n",
        "\n",
        "    return x\n",
        "\n",
        "model = ModelClass(img_size, 128, class_out)\n",
        "model = model.to(device)\n",
        "print(model)  # print the architecture\n",
        "\n",
        "#for param in model.parameters():  # you can use this to plot the actual weights/parameters\n",
        "#    print(param)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "WJsnjMeGAs-G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train the model"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "nLtNZzNZAs-G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "momentum = 0.9\n",
        "epochs = 10\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Qk7miQlxAs-H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [],
      "source": [
        "## compute accuracy\n",
        "def get_accuracy(logit, target, batch_size):\n",
        "    ''' Obtain accuracy for training round '''\n",
        "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
        "    accuracy = 100.0 * corrects/batch_size\n",
        "    return accuracy.item()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "hSkQxW2TAs-H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Training loop"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "4gdyLTh7As-I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "for epoch in range(epochs):\n",
        "  #Put the model in training mode\n",
        "  model = model.train()\n",
        "\n",
        "  train_running_loss = 0.0\n",
        "  train_acc = 0.0\n",
        "  for idx, (images, labels) in enumerate(trainloader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    ## forward + backprop + loss\n",
        "    logits = model(images)\n",
        "    loss = criterion(logits, labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    ## update model params\n",
        "    optimizer.step()\n",
        "\n",
        "    train_running_loss += loss.detach().item()\n",
        "    train_acc += get_accuracy(logits, labels, batch_size)\n",
        "\n",
        "  print('Epoch: %d | Loss: %.4f | Train Accuracy: %.2f' \\\n",
        "          %(epoch, train_running_loss / idx, train_acc/idx))\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qlM75dTcAs-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Analyse some training progress"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "fhnvB6uzAs-J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 86.76867686768676, in epoch: 9\n"
          ]
        }
      ],
      "source": [
        "model = model.eval()\n",
        "test_acc = 0.0\n",
        "for i, (images, labels) in enumerate(testloader, 0):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "    test_acc += get_accuracy(outputs, labels, 1)\n",
        "\n",
        "print(f\"Test Accuracy: {test_acc/i}, in epoch: {epoch}\")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "0UjNTtO0As-J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfff2df7-6fea-4f37-91af-53370d2ab9f4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Analyse the model"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "h4oqz4GkAs-J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "outputs": [],
      "source": [
        "model = model.eval()\n",
        "\n",
        "hist = {\n",
        "          0: {i:0 for i in range(10)},\n",
        "          1: {i:0 for i in range(10)},\n",
        "          2: {i:0 for i in range(10)},\n",
        "          3: {i:0 for i in range(10)},\n",
        "          4: {i:0 for i in range(10)},\n",
        "          5: {i:0 for i in range(10)},\n",
        "          6: {i:0 for i in range(10)},\n",
        "          7: {i:0 for i in range(10)},\n",
        "          8: {i:0 for i in range(10)},\n",
        "          9: {i:0 for i in range(10)}\n",
        "        }\n",
        "\n",
        "logits = []\n",
        "\n",
        "for (images, labels) in testloader:\n",
        "  images = images.to(device)\n",
        "  labels = labels.to(device)\n",
        "  outputs = model(images)\n",
        "  logits.append(outputs.tolist()[0])\n",
        "  pred = torch.argmax(outputs).item()\n",
        "  hist[labels[0].item()][pred] += 1"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "47pjaChRAs-K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Histogram of predictions"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "NzLXzRIxAs-K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "fig.set_figheight(15)\n",
        "fig.set_figwidth(15)\n",
        "for idx, (key, val) in enumerate(hist.items()):\n",
        "  ax = fig.add_subplot(3, 4, idx+1)\n",
        "  ax.bar(list(val.keys()), val.values(), color='r')\n",
        "  ax.set_title(f\"Prediction for {key}\")\n",
        "  ax.set_xticks(range(0,10))\n",
        "  ax.set_ylim(0, 1200)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Bw0uc0P5As-K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Visualise some prediction structure"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "DAIIO-q_As-L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "#tsne = TSNE(n_components=2, learning_rate='auto', init='pca')\n",
        "tsne = TSNE()\n",
        "\n",
        "palette = sns.color_palette(\"bright\", 10)\n",
        "\n",
        "y = testloader.dataset.targets.tolist()\n",
        "X_embedded_true = tsne.fit_transform(torch.flatten(testloader.dataset.data,start_dim=1))\n",
        "X_embedded_pred = tsne.fit_transform(np.array(logits))\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 15))\n",
        "fig.suptitle('Distribution of digits based on: ')\n",
        "\n",
        "sns.scatterplot(ax=axes[0], x=X_embedded_true[:,0], y=X_embedded_true[:,1], hue=y, legend='full', palette=palette)\n",
        "axes[0].set_title(\"Ground truth image features\")\n",
        "\n",
        "sns.scatterplot(ax=axes[1], x=X_embedded_pred[:,0], y=X_embedded_pred[:,1], hue=y, legend='full', palette=palette)\n",
        "axes[1].set_title(\"Predicted logits\")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "_-40ZckcAs-L"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}